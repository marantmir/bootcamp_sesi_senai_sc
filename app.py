import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import plotly.express as px
import plotly.graph_objects as go
import requests
import joblib
import os

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Sistema de Manuten√ß√£o Preditiva",
    page_icon="üîß",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üîß Sistema Inteligente de Manuten√ß√£o Preditiva")
st.markdown("---")

# Verificar se os arquivos existem localmente
arquivo_treino_existe = os.path.exists("bootcamp_train.csv")
arquivo_teste_existe = os.path.exists("bootcamp_test.csv")

# Barra lateral para configura√ß√µes
with st.sidebar:
    st.header("Configura√ß√µes do Projeto")
    
    # Informa√ß√µes sobre arquivos
    st.subheader("Status dos Arquivos")
    if arquivo_treino_existe:
        st.success("‚úÖ bootcamp_train.csv encontrado")
        # Apenas mostrar informa√ß√£o, n√£o carregar dados aqui
        try:
            dados_preview = pd.read_csv("bootcamp_train.csv", nrows=5)
            st.write(f"üìä Estrutura do arquivo: {len(dados_preview)} linhas preview")
        except:
            st.write("üìä Arquivo encontrado")
    else:
        st.error("‚ùå bootcamp_train.csv n√£o encontrado")
        
    if arquivo_teste_existe:
        st.success("‚úÖ bootcamp_test.csv encontrado")
        # Apenas mostrar informa√ß√£o, n√£o carregar dados aqui
        try:
            dados_preview = pd.read_csv("bootcamp_test.csv", nrows=5)
            st.write(f"üìà Estrutura do arquivo: {len(dados_preview)} linhas preview")
        except:
            st.write("üìà Arquivo encontrado")
    else:
        st.warning("‚ö†Ô∏è bootcamp_test.csv n√£o encontrado")
    
    # Configura√ß√µes de an√°lise
    st.subheader("Configura√ß√µes de An√°lise")
    opcao_analise = st.selectbox(
        "Tipo de An√°lise Explorat√≥ria:",
        ["Geral", "Por Tipo de M√°quina", "Por Tipo de Falha"]
    )
    
    # Configura√ß√µes do modelo
    st.subheader("Configura√ß√µes do Modelo")
    tipo_modelagem = st.selectbox(
        "Tipo de Modelagem:",
        ["Bin√°ria (Falha vs N√£o Falha)", "Multiclasse (Tipo de Falha)", "Multirr√≥tulo"]
    )
    
    tamanho_teste = st.slider("Percentual para Teste:", 10, 40, 20)
    estado_aleatorio = st.slider("Semente Aleat√≥ria:", 0, 100, 42)
    
    # Op√ß√µes de engenharia de caracter√≠sticas
    st.subheader("Engenharia de Caracter√≠sticas")
    usar_diferenca_temperatura = st.checkbox("Usar diferen√ßa de temperatura", value=True)
    usar_potencia = st.checkbox("Usar c√°lculo de pot√™ncia", value=True)
    
    # Configura√ß√£o da API
    st.subheader("Configura√ß√µes da API")
    url_api = st.text_input("URL da API de avalia√ß√£o:", "https://api-bootcamp-cdia.herokuapp.com/evaluate")

# Fun√ß√µes auxiliares
@st.cache_data
def carregar_dados():
    """Carrega os dados dos arquivos CSV locais"""
    try:
        dados_treino = pd.read_csv("bootcamp_train.csv")
        dados_teste = pd.read_csv("bootcamp_test.csv") if arquivo_teste_existe else None
        return dados_treino, dados_teste
    except Exception as e:
        st.error(f"Erro ao carregar arquivos: {e}")
        return None, None

def preprocessar_dados(df, eh_treino=True, usar_diff_temp=True, usar_pot=True):
    """Pr√©-processa os dados"""
    df_processado = df.copy()
    
    # Codificar tipo de m√°quina
    codificador = LabelEncoder()
    df_processado['tipo_codificado'] = codificador.fit_transform(df_processado['tipo'])
    
    # Calcular diferen√ßa de temperatura (se habilitado)
    if usar_diff_temp:
        df_processado['diferenca_temperatura'] = df_processado['temperatura_processo'] - df_processado['temperatura_ar']
    
    # Calcular pot√™ncia (se habilitado)
    if usar_pot:
        df_processado['potencia'] = df_processado['torque'] * df_processado['velocidade_rotacional']
    
    if eh_treino:
        # Calcular se h√° qualquer tipo de falha
        colunas_falhas = ['FDF', 'FDC', 'FP', 'FTE', 'FA']
        df_processado['qualquer_falha'] = df_processado[colunas_falhas].max(axis=1)
    
    return df_processado

def plotar_distribuicoes(df, coluna, titulo):
    """Plota distribui√ß√µes dos dados"""
    figura = px.histogram(df, x=coluna, title=titulo, nbins=50, marginal="box")
    figura.update_layout(bargap=0.1)
    return figura

def plotar_matriz_correlacao(df):
    """Plota matriz de correla√ß√£o"""
    df_numerico = df.select_dtypes(include=[np.number])
    correlacao = df_numerico.corr()
    
    figura = go.Figure(data=go.Heatmap(
        z=correlacao.values,
        x=correlacao.columns,
        y=correlacao.index,
        colorscale='RdBu_r',
        zmin=-1,
        zmax=1,
        colorbar=dict(title="Correla√ß√£o"),
        hoverongaps=False,
        hovertemplate='<b>X</b>: %{x}<br><b>Y</b>: %{y}<br><b>Correla√ß√£o</b>: %{z:.2f}<extra></extra>'
    ))
    
    figura.update_layout(
        title="Matriz de Correla√ß√£o",
        width=800,
        height=800
    )
    
    return figura

def plotar_matriz_confusao(y_real, y_previsto, rotulos):
    """Plota matriz de confus√£o"""
    matriz_confusao = confusion_matrix(y_real, y_previsto)
    figura = px.imshow(
        matriz_confusao, 
        text_auto=True,
        aspect="auto",
        x=rotulos,
        y=rotulos,
        title="Matriz de Confus√£o",
        color_continuous_scale='Blues'
    )
    figura.update_xaxes(title="Previsto")
    figura.update_yaxes(title="Real")
    return figura

def plotar_importancia_caracteristicas(importancia_caracteristicas):
    """Plota import√¢ncia das caracter√≠sticas"""
    figura = px.bar(
        importancia_caracteristicas, 
        x='importancia', 
        y='caracteristica',
        title='Import√¢ncia das Caracter√≠sticas no Modelo',
        orientation='h',
        color='importancia',
        color_continuous_scale='viridis'
    )
    figura.update_layout(yaxis={'categoryorder':'total ascending'})
    return figura

# Carregar dados
if arquivo_treino_existe:
    dados_treino, dados_teste = carregar_dados()
    
    if dados_treino is not None:
        dados_processados = preprocessar_dados(dados_treino, eh_treino=True, 
                                              usar_diff_temp=usar_diferenca_temperatura, 
                                              usar_pot=usar_potencia)
        
        # Exibir informa√ß√µes b√°sicas dos dados
        st.header("üìä An√°lise Explorat√≥ria dos Dados")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total de Amostras", dados_treino.shape[0])
        with col2:
            st.metric("Total de Caracter√≠sticas", dados_treino.shape[1])
        with col3:
            falhas = dados_processados['qualquer_falha'].sum()
            st.metric("M√°quinas com Falha", f"{falhas} ({falhas/dados_treino.shape[0]*100:.1f}%)")
        with col4:
            tipos_maquina = dados_treino['tipo'].nunique()
            st.metric("Tipos de M√°quina", tipos_maquina)
        
        # Abas para diferentes an√°lises
        aba1, aba2, aba3, aba4, aba5 = st.tabs(["Vis√£o Geral", "Distribui√ß√µes", "Correla√ß√µes", "An√°lise de Falhas", "Tipos de M√°quina"])
        
        with aba1:
            st.subheader("Visualiza√ß√£o dos Dados")
            st.dataframe(dados_treino.head(10))
            
            st.subheader("Informa√ß√µes Estat√≠sticas")
            st.dataframe(dados_treino.describe())
            
            st.subheader("Tipos de Dados e Valores Nulos")
            info_df = pd.DataFrame({
                'Tipo': dados_treino.dtypes,
                'Valores Nulos': dados_treino.isnull().sum(),
                'Percentual Nulos': (dados_treino.isnull().sum() / len(dados_treino)) * 100
            })
            st.dataframe(info_df)
        
        with aba2:
            st.subheader("Distribui√ß√£o das Vari√°veis Num√©ricas")
            
            colunas_numericas = ['temperatura_ar', 'temperatura_processo', 'umidade_relativa', 
                               'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']
            
            colunas_por_linha = 2
            for i in range(0, len(colunas_numericas), colunas_por_linha):
                colunas = st.columns(colunas_por_linha)
                for j, coluna in enumerate(colunas_numericas[i:i+colunas_por_linha]):
                    with colunas[j]:
                        figura = plotar_distribuicoes(dados_treino, coluna, f"Distribui√ß√£o de {coluna}")
                        st.plotly_chart(figura, use_container_width=True)
        
        with aba3:
            st.subheader("Matriz de Correla√ß√£o")
            figura = plotar_matriz_correlacao(dados_processados)
            st.plotly_chart(figura, use_container_width=True)
        
        with aba4:
            st.subheader("An√°lise de Falhas")
            
            # Contagem de falhas por tipo
            colunas_falhas = ['FDF', 'FDC', 'FP', 'FTE', 'FA']
            contagem_falhas = dados_treino[colunas_falhas].sum()
            
            figura = px.pie(
                values=contagem_falhas.values,
                names=contagem_falhas.index,
                title="Distribui√ß√£o de Tipos de Falha"
            )
            st.plotly_chart(figura, use_container_width=True)
            
            # Rela√ß√£o entre vari√°veis e falhas
            st.subheader("Rela√ß√£o entre Vari√°veis e Falhas")
            variavel_selecionada = st.selectbox("Selecione a vari√°vel:", colunas_numericas, key="var_select")
            
            figura = px.box(
                dados_treino, 
                x='falha_maquina', 
                y=variavel_selecionada,
                title=f"{variavel_selecionada} vs Falha de M√°quina",
                color='falha_maquina'
            )
            st.plotly_chart(figura, use_container_width=True)
        
        with aba5:
            st.subheader("An√°lise por Tipo de M√°quina")
            
            # Distribui√ß√£o por tipo de m√°quina
            contagem_tipos = dados_treino['tipo'].value_counts()
            figura = px.pie(
                values=contagem_tipos.values,
                names=contagem_tipos.index,
                title="Distribui√ß√£o por Tipo de M√°quina"
            )
            st.plotly_chart(figura, use_container_width=True)
            
            # Falhas por tipo de m√°quina
            falhas_por_tipo = dados_treino.groupby('tipo')['falha_maquina'].mean() * 100
            figura = px.bar(
                x=falhas_por_tipo.index,
                y=falhas_por_tipo.values,
                title="Percentual de Falhas por Tipo de M√°quina",
                labels={'x': 'Tipo de M√°quina', 'y': 'Percentual de Falhas (%)'}
            )
            st.plotly_chart(figura, use_container_width=True)
        
        # Divis√£o dos dados e treinamento do modelo
        st.header("ü§ñ Modelagem Preditiva")
        
        # Selecionar caracter√≠sticas baseado nas op√ß√µes
        caracteristicas = ['tipo_codificado', 'temperatura_ar', 'temperatura_processo', 'umidade_relativa',
                         'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']
        
        if usar_diferenca_temperatura:
            caracteristicas.append('diferenca_temperatura')
        if usar_potencia:
            caracteristicas.append('potencia')
        
        if tipo_modelagem == "Bin√°ria (Falha vs N√£o Falha)":
            alvo = 'qualquer_falha'
            modelo = RandomForestClassifier(n_estimators=100, random_state=estado_aleatorio, class_weight='balanced')
            tipo_problema = 'binario'
        elif tipo_modelagem == "Multiclasse (Tipo de Falha)":
            # Criar uma coluna com o tipo de falha predominante
            colunas_falhas = ['FDF', 'FDC', 'FP', 'FTE', 'FA']
            dados_processados['tipo_falha'] = dados_processados[colunas_falhas].idxmax(axis=1)
            # Se n√£o h√° falha, marca como 'NF'
            dados_processados.loc[dados_processados['qualquer_falha'] == 0, 'tipo_falha'] = 'NF'
            
            codificador_falha = LabelEncoder()
            dados_processados['tipo_falha_codificado'] = codificador_falha.fit_transform(dados_processados['tipo_falha'])
            
            alvo = 'tipo_falha_codificado'
            modelo = RandomForestClassifier(n_estimators=100, random_state=estado_aleatorio, class_weight='balanced')
            tipo_problema = 'multiclasse'
        else:  # Multirr√≥tulo
            alvo = ['FDF', 'FDC', 'FP', 'FTE', 'FA']
            st.info("Para problemas multirr√≥tulo, treinaremos um modelo para cada tipo de falha.")
            tipo_problema = 'multirrotulo'
            modelos = {}
        
        # Dividir dados em treino e teste
        if tipo_problema != 'multirrotulo':
            X = dados_processados[caracteristicas]
            y = dados_processados[alvo]
            
            X_treino, X_teste, y_treino, y_teste = train_test_split(
                X, y, test_size=tamanho_teste/100, random_state=estado_aleatorio, stratify=y
            )
            
            # Treinar modelo
            with st.spinner('Treinando modelo...'):
                modelo.fit(X_treino, y_treino)
            
            # Fazer previs√µes
            y_previsto = modelo.predict(X_teste)
            y_probabilidade = modelo.predict_proba(X_teste)
            
            # Avaliar modelo
            acuracia = accuracy_score(y_teste, y_previsto)
            
            st.subheader("Resultados do Modelo")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Acur√°cia do Modelo", f"{acuracia:.4f}")
            
            with col2:
                st.metric("Amostras de Treino", X_treino.shape[0])
            
            with col3:
                st.metric("Amostras de Teste", X_teste.shape[0])
            
            # Matriz de confus√£o
            if tipo_problema == 'binario':
                rotulos = ['Sem Falha', 'Com Falha']
            else:
                rotulos = list(codificador_falha.classes_)
            
            figura = plotar_matriz_confusao(y_teste, y_previsto, rotulos)
            st.plotly_chart(figura, use_container_width=True)
            
            # Relat√≥rio de classifica√ß√£o
            st.subheader("Relat√≥rio de Classifica√ß√£o")
            relatorio = classification_report(y_teste, y_previsto, target_names=rotulos, output_dict=True)
            relatorio_df = pd.DataFrame(relatorio).transpose()
            st.dataframe(relatorio_df)
            
            # Import√¢ncia das caracter√≠sticas
            st.subheader("Import√¢ncia das Caracter√≠sticas")
            importancia_caracteristicas = pd.DataFrame({
                'caracteristica': caracteristicas,
                'importancia': modelo.feature_importances_
            }).sort_values('importancia', ascending=False)
            
            figura = plotar_importancia_caracteristicas(importancia_caracteristicas)
            st.plotly_chart(figura, use_container_width=True)
            
            # Mostrar caracter√≠sticas mais importantes
            st.write("Caracter√≠sticas mais importantes:")
            for i, linha in importancia_caracteristicas.head(5).iterrows():
                st.write(f"{i+1}. {linha['caracteristica']}: {linha['importancia']:.4f}")
        
        # Processar dados de teste se dispon√≠veis
        if arquivo_teste_existe and dados_teste is not None:
            st.header("üì§ Previs√µes para Dados de Teste")
            
            dados_teste_processados = preprocessar_dados(dados_teste, eh_treino=False, 
                                                       usar_diff_temp=usar_diferenca_temperatura, 
                                                       usar_pot=usar_potencia)
            
            # Garantir que temos as mesmas caracter√≠sticas
            X_teste_novo = dados_teste_processados[caracteristicas]
            
            if tipo_problema != 'multirrotulo':
                # Fazer previs√µes
                previsoes_teste = modelo.predict(X_teste_novo)
                probabilidades_teste = modelo.predict_proba(X_teste_novo)
                
                # Preparar resultados
                resultados_df = dados_teste.copy()
                
                if tipo_problema == 'binario':
                    resultados_df['falha_prevista'] = previsoes_teste
                    resultados_df['probabilidade_falha'] = probabilidades_teste[:, 1]
                else:
                    resultados_df['tipo_falha_previsto'] = codificador_falha.inverse_transform(previsoes_teste)
                    # Adicionar probabilidades para cada classe
                    for i, classe in enumerate(codificador_falha.classes_):
                        resultados_df[f'probabilidade_{classe}'] = probabilidades_teste[:, i]
                
                # Exibir resultados
                st.subheader("Previs√µes para os Dados de Teste")
                st.dataframe(resultados_df.head(10))
                
                # Estat√≠sticas das previs√µes
                if tipo_problema == 'binario':
                    falhas_previstas = resultados_df['falha_prevista'].sum()
                    st.metric("Falhas Previstas", f"{falhas_previstas} ({falhas_previstas/len(resultados_df)*100:.1f}%)")
                
                # Bot√£o para download dos resultados
                csv = resultados_df.to_csv(index=False)
                st.download_button(
                    label="Download das Previs√µes (CSV)",
                    data=csv,
                    file_name="previsoes_teste.csv",
                    mime="text/csv"
                )
                
                # Bot√£o para enviar para la API
                if st.button("Enviar Previs√µes para API de Avalia√ß√£o"):
                    # Preparar dados no formato esperado pela API
                    dados_envio = resultados_df[['id']].copy()
                    
                    if tipo_problema == 'binario':
                        dados_envio['falha_maquina'] = resultados_df['falha_prevista']
                        # Para a API, precisamos preencher as colunas de falha espec√≠ficas
                        for coluna in ['FDF', 'FDC', 'FP', 'FTE', 'FA']:
                            dados_envio[coluna] = 0
                    else:
                        dados_envio['falha_maquina'] = (resultados_df['tipo_falha_previsto'] != 'NF').astype(int)
                        # Preencher as colunas de falha espec√≠ficas
                        for coluna in ['FDF', 'FDC', 'FP', 'FTE', 'FA']:
                            dados_envio[coluna] = (resultados_df['tipo_falha_previsto'] == coluna).astype(int)
                    
                    # Converter para formato JSON
                    dados_json = dados_envio.to_dict(orient='records')
                    
                    # Enviar para a API
                    try:
                        with st.spinner('Enviando previs√µes para a API...'):
                            resposta = requests.post(url_api, json=dados_json)
                        if resposta.status_code == 200:
                            st.success("‚úÖ Previs√µes enviadas com sucesso para a API!")
                            st.json(resposta.json())
                        else:
                            st.error(f"‚ùå Erro ao enviar previs√µes: {resposta.text}")
                    except Exception as e:
                        st.error(f"‚ùå Erro de conex√£o: {str(e)}")
            
            else:
                st.info("Para problemas multirr√≥tulo, √© necess√°rio implementar a l√≥gica espec√≠fica.")
        
        # Salvar modelo treinado
        if st.button("üíæ Salvar Modelo Treinado"):
            joblib.dump(modelo, 'modelo_treinado.pkl')
            st.success("‚úÖ Modelo salvo com sucesso como 'modelo_treinado.pkl'")
            
    else:
        st.error("Erro ao processar os dados de treino.")
else:
    st.error("Arquivo bootcamp_train.csv n√£o encontrado. Por favor, verifique se o arquivo est√° no diret√≥rio correto.")

# Rodap√©
st.markdown("---")
st.markdown(
    """
    **Projeto Final do Bootcamp de Ci√™ncia de Dados e IA**  
    *Sistema de Manuten√ß√£o Preditiva para M√°quinas Industrials*  
    Desenvolvido com Streamlit, Scikit-learn e Plotly
    """
)
