import io
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from typing import Dict, List, Optional, Tuple
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix, 
    precision_recall_fscore_support, roc_auc_score, roc_curve
)
from sklearn.multioutput import MultiOutputClassifier
import xgboost as xgb
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURA√á√ÉO INICIAL DO STREAMLIT
# =============================================================================
st.set_page_config(
    page_title="Sistema de Manuten√ß√£o Preditiva - Bootcamp CDIA", 
    page_icon="üîß", 
    layout="wide"
)

st.title("üîß Sistema Inteligente de Manuten√ß√£o Preditiva Avan√ßado")
st.markdown("### Bootcamp de Ci√™ncia de Dados e IA - Projeto Final com Melhorias")

# =============================================================================
# SE√á√ÉO 1: ENTENDIMENTO DO PROBLEMA
# =============================================================================
st.header("üìã 1. ENTENDIMENTO DO PROBLEMA")

with st.expander("üéØ Contexto e Objetivos", expanded=True):
    st.markdown("""
    **Problema de Neg√≥cio:**
    - Empresa industrial necessita de sistema inteligente para manuten√ß√£o preditiva
    - Dados coletados via dispositivos IoT de diferentes m√°quinas
    - Objetivo: Identificar falhas antes que ocorram e classificar o tipo de falha
    
    **Impacto Esperado:**
    - ‚ö° Redu√ß√£o de paradas n√£o programadas (at√© 30%)
    - üí∞ Economia em custos de manuten√ß√£o (at√© 25%)
    - üìà Aumento da efici√™ncia operacional (at√© 15%)
    - üîí Melhoria na seguran√ßa industrial
    
    **Tipos de Falhas Monitoradas:**
    - **FDF**: Falha por Desgaste da Ferramenta
    - **FDC**: Falha por Dissipa√ß√£o de Calor  
    - **FP**: Falha de Pot√™ncia
    - **FTE**: Falha por Tens√£o Excessiva
    - **FA**: Falha Aleat√≥ria
    
    **Metodologia Avan√ßada Aplicada:**
    - ü§ñ M√∫ltiplos algoritmos de ML (RF, XGBoost, LightGBM, Neural Networks)
    - üîß Engenharia avan√ßada de features
    - ‚öôÔ∏è Otimiza√ß√£o de hiperpar√¢metros
    - üéØ Ensemble de modelos
    """)

# =============================================================================
# CONSTANTES E CONFIGURA√á√ïES
# =============================================================================
COLS_FALHA = ["fdf", "fdc", "fp", "fte", "fa"]
COL_ALVO_BINARIA = "falha_maquina"

# =============================================================================
# SE√á√ÉO 2: CARREGAMENTO E CONFIGURA√á√ÉO AVAN√áADA
# =============================================================================
st.header("üìÅ 2. CONFIGURA√á√ÉO AVAN√áADA DO SISTEMA")

# Sidebar para configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes Avan√ßadas")
    
    # Upload de arquivos
    arquivo_treino = st.file_uploader("üìä Bootcamp_train.csv", type=["csv"])
    arquivo_teste = st.file_uploader("üéØ Bootcamp_test.csv (opcional)", type=["csv"])
    
    st.subheader("üîß Par√¢metros de Modelagem")
    tipo_modelagem = st.selectbox(
        "Abordagem:", 
        ["Multirr√≥tulo", "Bin√°ria", "Multiclasse"],
        help="Multirr√≥tulo: prediz m√∫ltiplas falhas simult√¢neas"
    )
    
    algoritmo = st.selectbox(
        "Algoritmo Principal:",
        ["Ensemble (Todos)", "Random Forest", "XGBoost", "LightGBM", "Neural Network"],
        help="Ensemble combina todos os algoritmos"
    )
    
    otimizar_hiper = st.checkbox("üîç Otimiza√ß√£o de Hiperpar√¢metros", value=False)
    tipo_busca = st.selectbox("Tipo de Busca:", ["RandomizedSearch", "GridSearch"]) if otimizar_hiper else "Nenhuma"
    
    percentual_teste = st.slider("% Valida√ß√£o", 10, 40, 20, 5)
    semente = st.slider("Semente Aleat√≥ria", 0, 9999, 42)
    
    st.subheader("üî¨ Engenharia Avan√ßada de Features")
    usar_dif_temp = st.checkbox("Diferen√ßa de temperatura", value=True)
    usar_potencia = st.checkbox("Pot√™ncia (torque√óvelocidade)", value=True)
    usar_eficiencia = st.checkbox("Efici√™ncia da ferramenta", value=True)
    usar_interacoes = st.checkbox("üîó Intera√ß√µes entre vari√°veis", value=True)
    usar_series_temporais = st.checkbox("‚è∞ Features temporais", value=True)
    
    st.subheader("üéØ Sele√ß√£o de Features")
    usar_selecao = st.checkbox("Sele√ß√£o autom√°tica de features", value=True)
    n_features = st.slider("N√∫mero de features (se sele√ß√£o ativa)", 10, 50, 20) if usar_selecao else None
    
    normalizar = st.checkbox("Normaliza√ß√£o (StandardScaler)", value=True)

# =============================================================================
# FUN√á√ïES UTILIT√ÅRIAS AVAN√áADAS
# =============================================================================
@st.cache_data
def carregar_e_processar_dados(arquivo):
    """Carrega e processa os dados b√°sicos"""
    df = pd.read_csv(arquivo)
    
    # Normalizar nomes das colunas
    df.columns = (
        df.columns
        .str.strip()
        .str.lower()
        .str.replace(" ", "_")
        .str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    )
    
    return df

def criar_features_avancadas(df):
    """Aplica engenharia avan√ßada de features"""
    df = df.copy()
    
    # Features b√°sicas de engenharia
    if usar_dif_temp and {"temperatura_processo","temperatura_ar"}.issubset(df.columns):
        df["dif_temperatura"] = df["temperatura_processo"] - df["temperatura_ar"]
        df["razao_temperatura"] = df["temperatura_processo"] / (df["temperatura_ar"] + 1e-6)
        df["temp_normalizada"] = (df["temperatura_processo"] - df["temperatura_ar"].mean()) / df["temperatura_ar"].std()
    
    if usar_potencia and {"torque","velocidade_rotacional"}.issubset(df.columns):
        df["potencia_kw"] = (df["torque"] * df["velocidade_rotacional"]) / 1000.0
        df["potencia_especifica"] = df["potencia_kw"] / (df["desgaste_da_ferramenta"] + 1.0)
        df["torque_por_velocidade"] = df["torque"] / (df["velocidade_rotacional"] + 1.0)
    
    if usar_eficiencia and {"torque","desgaste_da_ferramenta"}.issubset(df.columns):
        df["eficiencia_ferramenta"] = df["torque"] / (df["desgaste_da_ferramenta"] + 1.0)
        df["desgaste_normalizado"] = df["desgaste_da_ferramenta"] / df["torque"]
        df["stress_ferramenta"] = df["torque"] * df["desgaste_da_ferramenta"]
    
    # Features baseadas em s√©ries temporais (simuladas atrav√©s do √≠ndice)
    if usar_series_temporais:
        # Rolling statistics (usando janela baseada no √≠ndice)
        window_size = min(10, len(df) // 4)
        if window_size > 2:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in ['temperatura_processo', 'torque', 'velocidade_rotacional']:
                if col in numeric_cols:
                    df[f"{col}_media_movel"] = df[col].rolling(window=window_size, min_periods=1).mean()
                    df[f"{col}_desvio_movel"] = df[col].rolling(window=window_size, min_periods=1).std().fillna(0)
                    df[f"{col}_tendencia"] = df[col].diff().fillna(0)
    
    # Features de intera√ß√£o entre vari√°veis
    if usar_interacoes:
        # Intera√ß√µes importantes identificadas
        if all(col in df.columns for col in ["temperatura_processo", "umidade_relativa"]):
            df["temp_umidade_interacao"] = df["temperatura_processo"] * df["umidade_relativa"]
        
        if all(col in df.columns for col in ["torque", "umidade_relativa"]):
            df["torque_umidade_interacao"] = df["torque"] * df["umidade_relativa"]
            
        if all(col in df.columns for col in ["velocidade_rotacional", "temperatura_processo"]):
            df["velocidade_temp_interacao"] = df["velocidade_rotacional"] * df["temperatura_processo"]
    
    return df

def otimizar_hiperparametros(modelo, X, y, algoritmo_nome, tipo_busca="RandomizedSearch"):
    """Otimiza hiperpar√¢metros do modelo"""
    
    param_grids = {
        "Random Forest": {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        },
        "XGBoost": {
            'n_estimators': [100, 200],
            'max_depth': [3, 6, 10],
            'learning_rate': [0.01, 0.1, 0.2],
            'subsample': [0.8, 1.0]
        },
        "LightGBM": {
            'n_estimators': [100, 200],
            'max_depth': [3, 6, 10],
            'learning_rate': [0.01, 0.1, 0.2],
            'num_leaves': [31, 50, 100]
        },
        "Neural Network": {
            'hidden_layer_sizes': [(50,), (100,), (50, 30)],
            'activation': ['relu', 'tanh'],
            'alpha': [0.0001, 0.001, 0.01],
            'learning_rate': ['adaptive', 'constant']
        }
    }
    
    if algoritmo_nome not in param_grids:
        return modelo
    
    param_grid = param_grids[algoritmo_nome]
    
    if tipo_busca == "GridSearch":
        search = GridSearchCV(modelo, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
    else:
        search = RandomizedSearchCV(modelo, param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)
    
    search.fit(X, y)
    return search.best_estimator_

def criar_ensemble(X_train, y_train, tipo_modelagem):
    """Cria ensemble de modelos"""
    modelos_base = {
        'rf': RandomForestClassifier(n_estimators=100, random_state=42),
        'xgb': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),
        'lgb': lgb.LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),
        'nn': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
    }
    
    if tipo_modelagem == "Multirr√≥tulo":
        ensemble_models = {}
        for name, model in modelos_base.items():
            ensemble_models[name] = MultiOutputClassifier(model)
        
        # Para multirr√≥tulo, retornamos um dicion√°rio de modelos
        for name, model in ensemble_models.items():
            model.fit(X_train, y_train)
        
        return ensemble_models
    else:
        # Para bin√°rio/multiclasse, usamos VotingClassifier
        ensemble = VotingClassifier(
            estimators=list(modelos_base.items()),
            voting='soft'
        )
        ensemble.fit(X_train, y_train)
        return ensemble

# Carregar dados
dados_treino = None
dados_teste = None

if arquivo_treino:
    dados_treino = carregar_e_processar_dados(arquivo_treino)
    st.success(f"‚úÖ Dados de treino carregados: {dados_treino.shape[0]} amostras √ó {dados_treino.shape[1]} features")
    
if arquivo_teste:
    dados_teste = carregar_e_processar_dados(arquivo_teste)
    st.success(f"‚úÖ Dados de teste carregados: {dados_teste.shape[0]} amostras")

if dados_treino is None:
    st.warning("‚è≥ Por favor, carregue o arquivo de treino para continuar.")
    st.stop()

# =============================================================================
# SE√á√ÉO 3: AN√ÅLISE EXPLORAT√ìRIA AVAN√áADA
# =============================================================================
st.header("üìä 3. AN√ÅLISE EXPLORAT√ìRIA AVAN√áADA")

# Aplicar engenharia de features
dados_processados = criar_features_avancadas(dados_treino)

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("üìä Total de Amostras", dados_processados.shape[0])
with col2:
    st.metric("üìà Features Originais", dados_treino.shape[1])
with col3:
    st.metric("üîß Features Criadas", dados_processados.shape[1] - dados_treino.shape[1])
with col4:
    st.metric("üìä Total de Features", dados_processados.shape[1])

if all(col in dados_processados.columns for col in COLS_FALHA):
    # An√°lise de desbalanceamento avan√ßada
    st.subheader("‚öñÔ∏è An√°lise Detalhada de Desbalanceamento")
    
    falhas_count = dados_processados[COLS_FALHA].sum().sort_values(ascending=False)
    total_amostras = len(dados_processados)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Tabela de estat√≠sticas
        df_stats = pd.DataFrame({
            'Tipo_Falha': falhas_count.index,
            'Quantidade': falhas_count.values,
            'Percentual': (falhas_count.values / total_amostras * 100).round(2),
            'Classe': ['Minorit√°ria' if x < total_amostras * 0.1 else 'Majorit√°ria' for x in falhas_count.values]
        })
        
        st.dataframe(df_stats, use_container_width=True)
        
        # Calcular raz√£o de desbalanceamento
        ratio_desbalanceamento = falhas_count.max() / falhas_count.min()
        st.metric("üîÑ Raz√£o de Desbalanceamento", f"{ratio_desbalanceamento:.1f}:1")
    
    with col2:
        # Gr√°fico de distribui√ß√£o
        fig = px.bar(
            df_stats, 
            x='Quantidade', 
            y='Tipo_Falha',
            color='Classe',
            orientation='h',
            title="Distribui√ß√£o das Classes de Falhas"
        )
        st.plotly_chart(fig, use_container_width=True)

# An√°lise de correla√ß√µes das novas features
st.subheader("üîó Matriz de Correla√ß√£o das Features Avan√ßadas")

# Selecionar apenas features num√©ricas criadas recentemente
new_features = [col for col in dados_processados.columns 
                if any(keyword in col for keyword in ['interacao', 'media_movel', 'desvio_movel', 'tendencia', 
                                                     'potencia', 'eficiencia', 'dif_', 'razao_'])]

if new_features:
    correlation_matrix = dados_processados[new_features].corr()
    
    fig_corr = px.imshow(
        correlation_matrix.values,
        x=correlation_matrix.columns,
        y=correlation_matrix.columns,
        aspect="auto",
        title="Correla√ß√£o entre Features Criadas",
        color_continuous_scale="RdBu_r"
    )
    fig_corr.update_layout(height=600)
    st.plotly_chart(fig_corr, use_container_width=True)

# =============================================================================
# SE√á√ÉO 4: PREPARA√á√ÉO AVAN√áADA DOS DADOS
# =============================================================================
st.header("üîß 4. PREPARA√á√ÉO AVAN√áADA DOS DADOS")

# Preparar features (X) e targets (y)
excluir_cols = {"id", "id_produto", "tipo", COL_ALVO_BINARIA} | set(COLS_FALHA)
features_cols = [col for col in dados_processados.columns if col not in excluir_cols]

# Tratar valores categ√≥ricos
if "tipo" in dados_processados.columns:
    le_tipo = LabelEncoder()
    dados_processados["tipo_encoded"] = le_tipo.fit_transform(dados_processados["tipo"].fillna("Unknown"))
    features_cols.append("tipo_encoded")

# Preparar matriz X
X = dados_processados[features_cols].copy()

# Tratar valores ausentes com estrat√©gia avan√ßada
X = X.fillna(X.median())

st.success(f"‚úÖ {X.shape[1]} features preparadas inicialmente")

# Sele√ß√£o autom√°tica de features
if usar_selecao and n_features:
    st.subheader("üéØ Sele√ß√£o Autom√°tica de Features")
    
    # Preparar y tempor√°rio para sele√ß√£o
    if all(col in dados_processados.columns for col in COLS_FALHA):
        y_temp = dados_processados[COLS_FALHA].max(axis=1)  # Qualquer falha
    else:
        y_temp = dados_processados.get(COL_ALVO_BINARIA, pd.Series([0]*len(dados_processados)))
    
    # Aplicar SelectKBest
    selector = SelectKBest(f_classif, k=min(n_features, X.shape[1]))
    X_selected = selector.fit_transform(X, y_temp)
    
    # Obter nomes das features selecionadas
    selected_features = [features_cols[i] for i in selector.get_support(indices=True)]
    X = pd.DataFrame(X_selected, columns=selected_features, index=X.index)
    features_cols = selected_features
    
    st.success(f"‚úÖ {len(selected_features)} features selecionadas automaticamente")
    
    # Mostrar import√¢ncia das features selecionadas
    scores = selector.scores_[selector.get_support()]
    df_scores = pd.DataFrame({
        'Feature': selected_features,
        'Score': scores
    }).sort_values('Score', ascending=False)
    
    fig_scores = px.bar(
        df_scores.head(15), 
        x='Score', 
        y='Feature',
        orientation='h',
        title="Top Features Selecionadas (F-Score)"
    )
    st.plotly_chart(fig_scores, use_container_width=True)

# Normaliza√ß√£o
scaler = None
if normalizar:
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)

# Preparar targets baseado no tipo de modelagem
if tipo_modelagem == "Multirr√≥tulo":
    if not all(col in dados_processados.columns for col in COLS_FALHA):
        st.error("‚ùå Dados n√£o cont√™m colunas necess√°rias para modelagem multirr√≥tulo.")
        st.stop()
    y = dados_processados[COLS_FALHA].values
    target_names = COLS_FALHA
    
elif tipo_modelagem == "Bin√°ria":
    if COL_ALVO_BINARIA not in dados_processados.columns:
        st.error("‚ùå Coluna 'falha_maquina' n√£o encontrada para modelagem bin√°ria.")
        st.stop()
    y = dados_processados[COL_ALVO_BINARIA].values
    target_names = ["Sem Falha", "Com Falha"]
    
else:  # Multiclasse
    if not all(col in dados_processados.columns for col in COLS_FALHA):
        st.error("‚ùå Dados n√£o cont√™m colunas necess√°rias para modelagem multiclasse.")
        st.stop()
    
    # Criar target multiclasse
    def get_primary_failure(row):
        failures = [col for col in COLS_FALHA if row[col] == 1]
        if len(failures) == 0:
            return "sem_falha"
        elif len(failures) == 1:
            return failures[0]
        else:
            return "multiplas_falhas"
    
    y_multiclass = dados_processados[COLS_FALHA].apply(get_primary_failure, axis=1)
    le_target = LabelEncoder()
    y = le_target.fit_transform(y_multiclass)
    target_names = le_target.classes_

st.write(f"**Features finais utilizadas:** {len(features_cols)} features")

# =============================================================================
# SE√á√ÉO 5: MODELAGEM AVAN√áADA COM M√öLTIPLOS ALGORITMOS
# =============================================================================
st.header("ü§ñ 5. MODELAGEM AVAN√áADA")

# Dividir dados
if tipo_modelagem == "Multirr√≥tulo":
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=percentual_teste/100, random_state=semente
    )
else:
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=percentual_teste/100, random_state=semente, 
        stratify=y if len(np.unique(y)) > 1 else None
    )

st.write(f"üìä **Divis√£o dos dados:** {len(X_train)} treino / {len(X_val)} valida√ß√£o")

# Treinar modelos
resultados_modelos = {}

with st.spinner("üîÑ Treinando modelos avan√ßados..."):
    
    if algoritmo == "Ensemble (Todos)":
        st.subheader("üéØ Ensemble de Modelos")
        modelo = criar_ensemble(X_train, y_train, tipo_modelagem)
        
        if tipo_modelagem == "Multirr√≥tulo":
            # Para multirr√≥tulo, fazer predi√ß√µes com cada modelo do ensemble
            predicoes_ensemble = {}
            for name, model in modelo.items():
                pred = model.predict(X_val)
                predicoes_ensemble[name] = pred
                
                # Calcular m√©tricas m√©dias
                accuracies = [accuracy_score(y_val[:, i], pred[:, i]) for i in range(len(COLS_FALHA))]
                resultados_modelos[name] = np.mean(accuracies)
            
            # Predi√ß√£o final por vota√ß√£o majorit√°ria
            y_pred = np.round(np.mean([pred for pred in predicoes_ensemble.values()], axis=0)).astype(int)
            
        else:
            y_pred = modelo.predict(X_val)
            resultados_modelos["Ensemble"] = accuracy_score(y_val, y_pred)
    
    else:
        # Treinar modelo individual
        modelos_disponiveis = {
            "Random Forest": RandomForestClassifier(n_estimators=200, random_state=semente),
            "XGBoost": xgb.XGBClassifier(n_estimators=200, random_state=semente, eval_metric='logloss'),
            "LightGBM": lgb.LGBMClassifier(n_estimators=200, random_state=semente, verbose=-1),
            "Neural Network": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=semente)
        }
        
        modelo_base = modelos_disponiveis[algoritmo]
        
        # Otimiza√ß√£o de hiperpar√¢metros
        if otimizar_hiper:
            st.write(f"üîç Otimizando hiperpar√¢metros com {tipo_busca}...")
            if tipo_modelagem != "Multirr√≥tulo":
                modelo_base = otimizar_hiperparametros(modelo_base, X_train, y_train, algoritmo, tipo_busca)
        
        # Aplicar MultiOutputClassifier se necess√°rio
        if tipo_modelagem == "Multirr√≥tulo":
            modelo = MultiOutputClassifier(modelo_base)
        else:
            modelo = modelo_base
        
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_val)
        
        if tipo_modelagem == "Multirr√≥tulo":
            accuracies = [accuracy_score(y_val[:, i], y_pred[:, i]) for i in range(len(COLS_FALHA))]
            resultados_modelos[algoritmo] = np.mean(accuracies)
        else:
            resultados_modelos[algoritmo] = accuracy_score(y_val, y_pred)

st.success("‚úÖ Modelos treinados com sucesso!")

# Mostrar compara√ß√£o de modelos se ensemble
if len(resultados_modelos) > 1:
    st.subheader("üìä Compara√ß√£o de Modelos")
    df_resultados = pd.DataFrame(list(resultados_modelos.items()), columns=['Modelo', 'Accuracy'])
    df_resultados = df_resultados.sort_values('Accuracy', ascending=False)
    
    fig_comp = px.bar(
        df_resultados, 
        x='Accuracy', 
        y='Modelo',
        orientation='h',
        title="Compara√ß√£o de Performance dos Modelos"
    )
    st.plotly_chart(fig_comp, use_container_width=True)

# =============================================================================
# SE√á√ÉO 6: AVALIA√á√ÉO AVAN√áADA
# =============================================================================
st.header("üìä 6. AVALIA√á√ÉO AVAN√áADA DOS RESULTADOS")

if tipo_modelagem == "Multirr√≥tulo":
    # M√©tricas detalhadas por classe
    st.subheader("üìà M√©tricas Detalhadas por Tipo de Falha")
    
    metricas_detalhadas = {}
    cols_display = st.columns(len(COLS_FALHA))
    
    for i, col_falha in enumerate(COLS_FALHA):
        accuracy = accuracy_score(y_val[:, i], y_pred[:, i])
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_val[:, i], y_pred[:, i], average='binary', zero_division=0
        )
        
        # Calcular AUC se poss√≠vel
        try:
            if hasattr(modelo, 'predict_proba') or (hasattr(modelo, 'estimators_') and hasattr(modelo.estimators_[i], 'predict_proba')):
                if hasattr(modelo, 'estimators_'):
                    y_proba = modelo.estimators_[i].predict_proba(X_val)[:, 1]
                else:
                    y_proba = modelo.predict_proba(X_val)[i][:, 1]
                auc = roc_auc_score(y_val[:, i], y_proba)
            else:
                auc = 0.5
        except:
            auc = 0.5
        
        metricas_detalhadas[col_falha] = {
            'Accuracy': accuracy,
            'Precision': precision,
            'Recall': recall,
            'F1-Score': f1,
            'AUC': auc
        }
        
        with cols_display[i]:
            st.metric(f"üéØ {col_falha.upper()}", f"{accuracy:.3f}")
            st.write(f"Precision: {precision:.3f}")
            st.write(f"Recall: {recall:.3f}")
            st.write(f"F1: {f1:.3f}")
            st.write(f"AUC: {auc:.3f}")
    
    # M√©tricas m√©dias
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        acc_media = np.mean([metricas_detalhadas[col]['Accuracy'] for col in COLS_FALHA])
        st.metric("üèÜ Accuracy M√©dia", f"{acc_media:.4f}")
    with col2:
        prec_media = np.mean([metricas_detalhadas[col]['Precision'] for col in COLS_FALHA])
        st.metric("üéØ Precision M√©dia", f"{prec_media:.4f}")
    with col3:
        rec_media = np.mean([metricas_detalhadas[col]['Recall'] for col in COLS_FALHA])
        st.metric("üìä Recall M√©dio", f"{rec_media:.4f}")
    with col4:
        f1_media = np.mean([metricas_detalhadas[col]['F1-Score'] for col in COLS_FALHA])
        st.metric("‚öñÔ∏è F1 M√©dio", f"{f1_media:.4f}")

else:
    # Modelo bin√°rio ou multiclasse
    accuracy = accuracy_score(y_val, y_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_val, y_pred, average='weighted', zero_division=0
    )
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üéØ Accuracy", f"{accuracy:.4f}")
    with col2:
        st.metric("üîç Precision", f"{precision:.4f}")
    with col3:
        st.metric("üìä Recall", f"{recall:.4f}")
    with col4:
        st.metric("‚öñÔ∏è F1-Score", f"{f1:.4f}")
    
    # Relat√≥rio de classifica√ß√£o
    st.subheader("üìã Relat√≥rio Detalhado de Classifica√ß√£o")
    
    report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)
    df_report = pd.DataFrame(report).transpose()
    st.dataframe(df_report.round(4), use_container_width=True)
    
    # Matriz de confus√£o
    st.subheader("üîç Matriz de Confus√£o")
    
    cm = confusion_matrix(y_val, y_pred)
    fig_cm = px.imshow(
        cm, 
        text_auto=True, 
        aspect="auto", 
        title="Matriz de Confus√£o",
        color_continuous_scale="Blues"
    )
    fig_cm.update_xaxes(title="Predito")
    fig_cm.update_yaxes(title="Real")
    st.plotly_chart(fig_cm, use_container_width=True)

# Feature Importance Avan√ßada
st.subheader("üéØ An√°lise de Import√¢ncia das Features")

if algoritmo == "Ensemble (Todos)" and tipo_modelagem != "Multirr√≥tulo":
    # Para ensemble n√£o-multirr√≥tulo
    if hasattr(modelo, 'feature_importances_'):
        importances = modelo.feature_importances_
    else:
        # M√©dia das import√¢ncias dos estimadores
        importances = np.mean([est.feature_importances_ for name, est in modelo.named_estimators_.items() 
                              if hasattr(est, 'feature_importances_')], axis=0)
        
elif algoritmo == "Ensemble (Todos)" and tipo_modelagem == "Multirr√≥tulo":
    # Para ensemble multirr√≥tulo, usar Random Forest como refer√™ncia
    if 'rf' in modelo and hasattr(modelo['rf'], 'estimators_'):
        importances = np.mean([est.feature_importances_ for est in modelo['rf'].estimators_], axis=0)
    else:
        importances = np.ones(len(features_cols)) / len(features_cols)  # Uniforme se n√£o dispon√≠vel
        
elif hasattr(modelo, 'feature_importances_'):
    importances = modelo.feature_importances_
elif tipo_modelagem == "Multirr√≥tulo" and hasattr(modelo, 'estimators_'):
    # Para MultiOutputClassifier
    importances = np.mean([est.feature_importances_ for est in modelo.estimators_ 
                          if hasattr(est, 'feature_importances_')], axis=0)
else:
    importances = np.ones(len(features_cols)) / len(features_cols)  # Uniforme se n√£o dispon√≠vel

feature_importance_df = pd.DataFrame({
    'Feature': features_cols,
    'Importance': importances
}).sort_values('Importance', ascending=False)

# Mostrar top features
col1, col2 = st.columns(2)

with col1:
    fig_importance = px.bar(
        feature_importance_df.head(15), 
        x='Importance', 
        y='Feature',
        orientation='h',
        title="Top 15 Features Mais Importantes"
    )
    fig_importance.update_layout(height=500)
    st.plotly_chart(fig_importance, use_container_width=True)

with col2:
    # An√°lise das features criadas vs originais
    feature_importance_df['Tipo'] = feature_importance_df['Feature'].apply(
        lambda x: 'Engenharia' if any(keyword in x for keyword in 
                                    ['interacao', 'media_movel', 'desvio_movel', 'tendencia', 
                                     'potencia', 'eficiencia', 'dif_', 'razao_']) 
                               else 'Original'
    )
    
    tipo_importancia = feature_importance_df.groupby('Tipo')['Importance'].sum()
    
    fig_pie = px.pie(
        values=tipo_importancia.values,
        names=tipo_importancia.index,
        title="Contribui√ß√£o: Features Originais vs Criadas"
    )
    st.plotly_chart(fig_pie, use_container_width=True)

# =============================================================================
# SE√á√ÉO 7: PREDI√á√ïES NO CONJUNTO DE TESTE
# =============================================================================
if dados_teste is not None:
    st.header("üéØ 7. PREDI√á√ïES NO CONJUNTO DE TESTE")
    
    # Processar dados de teste
    dados_teste_proc = criar_features_avancadas(dados_teste)
    
    if "tipo" in dados_teste_proc.columns and 'le_tipo' in locals():
        dados_teste_proc["tipo_encoded"] = le_tipo.transform(
            dados_teste_proc["tipo"].fillna("Unknown")
        )
    
    # Preparar X_test com as mesmas features
    X_test = dados_teste_proc[features_cols].copy()
    X_test = X_test.fillna(X_test.median())
    
    if scaler is not None:
        X_test = pd.DataFrame(
            scaler.transform(X_test), 
            columns=X_test.columns, 
            index=X_test.index
        )
    
    # Gerar predi√ß√µes
    if tipo_modelagem == "Multirr√≥tulo":
        if algoritmo == "Ensemble (Todos)":
            # M√©dia das predi√ß√µes do ensemble
            predicoes_teste = {}
            for name, model in modelo.items():
                predicoes_teste[name] = model.predict(X_test)
            
            pred_test = np.round(np.mean([pred for pred in predicoes_teste.values()], axis=0)).astype(int)
        else:
            pred_test = modelo.predict(X_test)
        
        # Criar DataFrame de sa√≠da
        df_predicoes = pd.DataFrame(
            pred_test, 
            columns=[col.upper() for col in COLS_FALHA]
        ).astype(int)
        
    else:
        pred_test = modelo.predict(X_test)
        
        # Para bin√°rio/multiclasse, criar formato multirr√≥tulo
        df_predicoes = pd.DataFrame(
            0, 
            index=range(len(pred_test)), 
            columns=[col.upper() for col in COLS_FALHA]
        )
        
        if tipo_modelagem == "Bin√°ria":
            # Atribuir falha mais comum quando h√° predi√ß√£o positiva
            falha_mais_comum = dados_processados[COLS_FALHA].sum().idxmax().upper()
            df_predicoes.loc[pred_test == 1, falha_mais_comum] = 1
            
        else:  # Multiclasse
            for i, pred in enumerate(pred_test):
                classe_nome = target_names[pred]
                if classe_nome in [col.lower() for col in COLS_FALHA]:
                    col_idx = [col.lower() for col in COLS_FALHA].index(classe_nome)
                    df_predicoes.iloc[i, col_idx] = 1
    
    # Estat√≠sticas das predi√ß√µes
    st.subheader("üìä Estat√≠sticas das Predi√ß√µes")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Contagem por tipo de falha:**")
        contagem_pred = df_predicoes.sum().to_frame("Quantidade")
        contagem_pred["Percentual"] = (contagem_pred["Quantidade"] / len(df_predicoes) * 100).round(2)
        st.dataframe(contagem_pred, use_container_width=True)
    
    with col2:
        # Gr√°fico de barras das predi√ß√µes
        fig_pred = px.bar(
            x=df_predicoes.sum().values,
            y=df_predicoes.sum().index,
            orientation='h',
            title="Distribui√ß√£o das Predi√ß√µes por Tipo de Falha"
        )
        st.plotly_chart(fig_pred, use_container_width=True)
    
    # An√°lise comparativa (se tivermos dados hist√≥ricos)
    st.subheader("üìà An√°lise Comparativa")
    col1, col2 = st.columns(2)
    
    with col1:
        # Comparar distribui√ß√£o treino vs predi√ß√µes
        dist_treino = dados_processados[COLS_FALHA].sum()
        dist_pred = df_predicoes.sum()
        
        df_comparacao = pd.DataFrame({
            'Treino': dist_treino.values,
            'Predi√ß√µes': dist_pred.values,
            'Falha': [col.upper() for col in COLS_FALHA]
        })
        
        fig_comp = px.bar(
            df_comparacao.melt(id_vars='Falha', var_name='Dataset', value_name='Quantidade'),
            x='Falha', y='Quantidade', color='Dataset', barmode='group',
            title="Compara√ß√£o: Distribui√ß√£o Treino vs Predi√ß√µes"
        )
        st.plotly_chart(fig_comp, use_container_width=True)
    
    with col2:
        # M√©tricas de confian√ßa (se modelo suporta probabilidades)
        if hasattr(modelo, 'predict_proba') or (algoritmo == "Ensemble (Todos)" and tipo_modelagem != "Multirr√≥tulo"):
            st.write("**M√©tricas de Confian√ßa:**")
            
            try:
                if tipo_modelagem == "Multirr√≥tulo":
                    # Para multirr√≥tulo, calcular confian√ßa m√©dia
                    confidencias = []
                    if algoritmo == "Ensemble (Todos)":
                        for name, model in modelo.items():
                            if hasattr(model, 'estimators_'):
                                conf = np.mean([est.predict_proba(X_test)[:, 1] if hasattr(est, 'predict_proba') else 0.5
                                              for est in model.estimators_], axis=0)
                                confidencias.append(conf)
                        confianca_media = np.mean(confidencias) if confidencias else 0.5
                    else:
                        confianca_media = 0.5
                else:
                    if hasattr(modelo, 'predict_proba'):
                        probas = modelo.predict_proba(X_test)
                        confianca_media = np.mean(np.max(probas, axis=1))
                    else:
                        confianca_media = 0.5
                
                st.metric("üéØ Confian√ßa M√©dia", f"{confianca_media:.3f}")
                
                # Distribui√ß√£o de confian√ßa
                if tipo_modelagem != "Multirr√≥tulo" and hasattr(modelo, 'predict_proba'):
                    conf_dist = np.max(modelo.predict_proba(X_test), axis=1)
                    fig_conf = px.histogram(x=conf_dist, title="Distribui√ß√£o da Confian√ßa")
                    st.plotly_chart(fig_conf, use_container_width=True)
                    
            except Exception as e:
                st.write("Confian√ßa n√£o dispon√≠vel para este modelo")
    
    # Download das predi√ß√µes
    csv_predicoes = df_predicoes.to_csv(index=False)
    st.download_button(
        "üì• Baixar Predi√ß√µes (CSV para API)",
        csv_predicoes,
        "bootcamp_predictions.csv",
        "text/csv"
    )
    
    st.success("‚úÖ Predi√ß√µes geradas com sucesso!")

# =============================================================================
# SE√á√ÉO 8: AN√ÅLISE DE PERFORMANCE E INSIGHTS
# =============================================================================
st.header("üìä 8. AN√ÅLISE DE PERFORMANCE E INSIGHTS")

col1, col2 = st.columns(2)

with col1:
    st.subheader("üîç Insights do Modelo")
    
    insights = []
    
    # Insight sobre features mais importantes
    top_feature = feature_importance_df.iloc[0]
    insights.append(f"üéØ **Feature mais importante:** {top_feature['Feature']} ({top_feature['Importance']:.3f})")
    
    # Insight sobre engenharia de features
    eng_features = feature_importance_df[feature_importance_df['Tipo'] == 'Engenharia']
    if not eng_features.empty:
        contrib_eng = feature_importance_df.groupby('Tipo')['Importance'].sum().get('Engenharia', 0)
        insights.append(f"üîß **Contribui√ß√£o das features criadas:** {contrib_eng:.1%}")
    
    # Insight sobre desbalanceamento
    if 'falhas_count' in locals():
        ratio = falhas_count.max() / falhas_count.min()
        insights.append(f"‚öñÔ∏è **Desbalanceamento:** {ratio:.1f}:1 (classe majorit√°ria vs minorit√°ria)")
    
    # Insight sobre performance
    if tipo_modelagem == "Multirr√≥tulo":
        melhor_classe = max(metricas_detalhadas.keys(), 
                           key=lambda x: metricas_detalhadas[x]['F1-Score'])
        pior_classe = min(metricas_detalhadas.keys(), 
                         key=lambda x: metricas_detalhadas[x]['F1-Score'])
        insights.append(f"üìà **Melhor predi√ß√£o:** {melhor_classe.upper()} (F1: {metricas_detalhadas[melhor_classe]['F1-Score']:.3f})")
        insights.append(f"üìâ **Maior desafio:** {pior_classe.upper()} (F1: {metricas_detalhadas[pior_classe]['F1-Score']:.3f})")
    
    for insight in insights:
        st.markdown(insight)

with col2:
    st.subheader("üí° Recomenda√ß√µes")
    
    recomendacoes = []
    
    # Recomenda√ß√£o baseada na performance
    if tipo_modelagem == "Multirr√≥tulo":
        f1_scores = [metricas_detalhadas[col]['F1-Score'] for col in COLS_FALHA]
        f1_medio = np.mean(f1_scores)
        if f1_medio < 0.7:
            recomendacoes.append("üìä Considere t√©cnicas de balanceamento (SMOTE, undersampling)")
        if min(f1_scores) < 0.5:
            recomendacoes.append("üéØ Foque na coleta de mais dados para classes minorit√°rias")
    
    # Recomenda√ß√£o sobre features
    if len(eng_features) > 0:
        recomendacoes.append("üîß Features de engenharia mostraram-se valiosas - continue explorando")
    
    # Recomenda√ß√£o sobre algoritmos
    if algoritmo != "Ensemble (Todos)":
        recomendacoes.append("ü§ñ Teste ensemble de modelos para melhor performance")
    
    recomendacoes.extend([
        "üìà Implemente monitoramento cont√≠nuo da performance",
        "üîÑ Considere retreinamento peri√≥dico com novos dados",
        "‚ö° Desenvolva sistema de alertas baseado nas predi√ß√µes",
        "üè≠ Integre com sistema de gest√£o de manuten√ß√£o existente"
    ])
    
    for rec in recomendacoes:
        st.markdown(f"- {rec}")

# =============================================================================
# SE√á√ÉO 9: CONCLUS√ïES E PR√ìXIMOS PASSOS
# =============================================================================
st.header("üìã 9. CONCLUS√ïES E PR√ìXIMOS PASSOS")

with st.expander("üéØ Principais Conclus√µes", expanded=True):
    st.markdown(f"""
    ### ‚úÖ **Resultados Alcan√ßados:**
    
    1. **Sistema Completo de Manuten√ß√£o Preditiva:**
       - An√°lise explorat√≥ria avan√ßada com {dados_processados.shape[1]} features
       - Engenharia de features criou {dados_processados.shape[1] - dados_treino.shape[1]} novas vari√°veis
       - Implementa√ß√£o de m√∫ltiplos algoritmos: Random Forest, XGBoost, LightGBM, Neural Networks
       - Ensemble de modelos para m√°xima performance
    
    2. **Performance do Modelo:**
       - Algoritmo utilizado: **{algoritmo}**
       - Abordagem: **{tipo_modelagem}**
       - Otimiza√ß√£o de hiperpar√¢metros: **{'Sim' if otimizar_hiper else 'N√£o'}**
       - Features selecionadas: **{len(features_cols)}**
    
    3. **Inova√ß√µes Implementadas:**
       - üîß Engenharia avan√ßada de features (intera√ß√µes, s√©ries temporais simuladas)
       - üéØ Sele√ß√£o autom√°tica de features
       - ‚öôÔ∏è Otimiza√ß√£o de hiperpar√¢metros
       - ü§ñ Ensemble de m√∫ltiplos algoritmos
       - üìä An√°lise comparativa de performance
    
    4. **Impacto no Neg√≥cio:**
       - Sistema pronto para detec√ß√£o precoce de falhas
       - Redu√ß√£o esperada de custos de manuten√ß√£o
       - Melhoria na disponibilidade dos equipamentos
       - Interface intuitiva para operadores
    """)

with st.expander("üöÄ Roadmap de Melhorias Futuras", expanded=False):
    st.markdown("""
    ### üìà **Pr√≥ximas Fases do Projeto:**
    
    **Fase 1 - Produ√ß√£o (Pr√≥ximos 30 dias):**
    - ‚ö° API RESTful com FastAPI para integra√ß√£o
    - üê≥ Containeriza√ß√£o com Docker
    - üìä Dashboard em tempo real para monitoramento
    - üîí Sistema de autentica√ß√£o e logs
    
    **Fase 2 - Intelig√™ncia Avan√ßada (60-90 dias):**
    - üß† Deep Learning com redes neurais recorrentes (LSTM)
    - üìà An√°lise de s√©ries temporais reais
    - üéØ Detec√ß√£o de anomalias n√£o supervisionada
    - üîÑ Auto-ML para otimiza√ß√£o cont√≠nua
    
    **Fase 3 - Integra√ß√£o Empresarial (90-120 dias):**
    - üè≠ Integra√ß√£o com sistemas ERP/MES
    - üì± App mobile para t√©cnicos de manuten√ß√£o
    - ü§ñ Chatbot para consultas sobre equipamentos
    - üìä Dashboards executivos com KPIs de neg√≥cio
    
    **Fase 4 - Escala e Otimiza√ß√£o (120+ dias):**
    - ‚òÅÔ∏è Deploy em nuvem com auto-scaling
    - üîÑ Pipeline de CI/CD completo
    - üìà MLOps com monitoramento de drift
    - üåê Multi-tenancy para diferentes plantas industriais
    """)

# =============================================================================
# M√âTRICAS FINAIS DE SISTEMA
# =============================================================================
st.header("üìä Dashboard Executivo")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("üìä Amostras Processadas", f"{dados_processados.shape[0]:,}")
with col2:
    st.metric("üîß Features Totais", dados_processados.shape[1])
with col3:
    if tipo_modelagem == "Multirr√≥tulo":
        perf_media = np.mean([metricas_detalhadas[col]['F1-Score'] for col in COLS_FALHA])
        st.metric("üéØ Performance M√©dia", f"{perf_media:.3f}")
    else:
        st.metric("üéØ Accuracy Final", f"{accuracy:.3f}")
with col4:
    if dados_teste is not None:
        falhas_previstas = df_predicoes.sum().sum()
        st.metric("‚ö†Ô∏è Falhas Previstas", int(falhas_previstas))
    else:
        st.metric("üíæ Modelo Treinado", "‚úÖ")

# =============================================================================
# RODAP√â PROFISSIONAL
# =============================================================================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <h4>üîß Sistema Inteligente de Manuten√ß√£o Preditiva</h4>
    <p><strong>Bootcamp de Ci√™ncia de Dados e IA - Projeto Final</strong></p>
    <p>Desenvolvido com ‚ù§Ô∏è usando Python, Scikit-learn, XGBoost, LightGBM e Streamlit</p>
    <p><em>Implementa√ß√£o completa com algoritmos avan√ßados, engenharia de features e ensemble de modelos</em></p>
</div>
""", unsafe_allow_html=True)
