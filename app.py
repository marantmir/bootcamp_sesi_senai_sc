import io
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from typing import Dict, List, Optional, Tuple
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix, 
    precision_recall_fscore_support, roc_auc_score, roc_curve
)
from sklearn.multioutput import MultiOutputClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURA√á√ÉO INICIAL DO STREAMLIT
# =============================================================================
st.set_page_config(
    page_title="Sistema de Manuten√ß√£o Preditiva - Bootcamp CDIA", 
    page_icon="üîß", 
    layout="wide"
)

st.title("üîß Sistema Inteligente de Manuten√ß√£o Preditiva")
st.markdown("### Bootcamp de Ci√™ncia de Dados e IA - Projeto Final")

# =============================================================================
# SE√á√ÉO 1: ENTENDIMENTO DO PROBLEMA
# =============================================================================
st.header("üìã 1. ENTENDIMENTO DO PROBLEMA")

with st.expander("üéØ Contexto e Objetivos", expanded=True):
    st.markdown("""
    **Problema de Neg√≥cio:**
    - Empresa industrial necessita de sistema inteligente para manuten√ß√£o preditiva
    - Dados coletados via dispositivos IoT de diferentes m√°quinas
    - Objetivo: Identificar falhas antes que ocorram e classificar o tipo de falha
    
    **Impacto Esperado:**
    - ‚ö° Redu√ß√£o de paradas n√£o programadas (at√© 30%)
    - üí∞ Economia em custos de manuten√ß√£o (at√© 25%)
    - üìà Aumento da efici√™ncia operacional (at√© 15%)
    - üîí Melhoria na seguran√ßa industrial
    
    **Tipos de Falhas Monitoradas:**
    - **FDF**: Falha por Desgaste da Ferramenta
    - **FDC**: Falha por Dissipa√ß√£o de Calor  
    - **FP**: Falha de Pot√™ncia
    - **FTE**: Falha por Tens√£o Excessiva
    - **FA**: Falha Aleat√≥ria
    
    **Metodologia Aplicada:**
    - ü§ñ M√∫ltiplos algoritmos de ML (RF, Gradient Boosting, Neural Networks, SVM)
    - üîß Engenharia avan√ßada de features
    - ‚öôÔ∏è Otimiza√ß√£o de hiperpar√¢metros
    - üéØ Ensemble de modelos
    """)

# =============================================================================
# CONSTANTES E CONFIGURA√á√ïES
# =============================================================================
COLS_FALHA = ["fdf", "fdc", "fp", "fte", "fa"]
COL_ALVO_BINARIA = "falha_maquina"

# =============================================================================
# SE√á√ÉO 2: CARREGAMENTO E CONFIGURA√á√ÉO
# =============================================================================
st.header("üìÅ 2. CONFIGURA√á√ÉO DO SISTEMA")

# Sidebar para configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Upload de arquivos
    arquivo_treino = st.file_uploader("üìä Bootcamp_train.csv", type=["csv"])
    arquivo_teste = st.file_uploader("üéØ Bootcamp_test.csv (opcional)", type=["csv"])
    
    st.subheader("üîß Par√¢metros de Modelagem")
    tipo_modelagem = st.selectbox(
        "Abordagem:", 
        ["Multirr√≥tulo", "Bin√°ria", "Multiclasse"],
        help="Multirr√≥tulo: prediz m√∫ltiplas falhas simult√¢neas"
    )
    
    algoritmo = st.selectbox(
        "Algoritmo Principal:",
        ["Ensemble", "Random Forest", "Gradient Boosting", "Neural Network", "SVM"],
        help="Ensemble combina m√∫ltiplos algoritmos"
    )
    
    otimizar_hiper = st.checkbox("üîç Otimiza√ß√£o de Hiperpar√¢metros", value=False)
    tipo_busca = st.selectbox("Tipo de Busca:", ["RandomizedSearch", "GridSearch"]) if otimizar_hiper else "Nenhuma"
    
    percentual_teste = st.slider("% Valida√ß√£o", 10, 40, 20, 5)
    semente = st.slider("Semente Aleat√≥ria", 0, 9999, 42)
    
    st.subheader("üî¨ Engenharia de Features")
    usar_dif_temp = st.checkbox("Diferen√ßa de temperatura", value=True)
    usar_potencia = st.checkbox("Pot√™ncia (torque√óvelocidade)", value=True)
    usar_eficiencia = st.checkbox("Efici√™ncia da ferramenta", value=True)
    usar_interacoes = st.checkbox("üîó Intera√ß√µes entre vari√°veis", value=True)
    usar_series_temporais = st.checkbox("‚è∞ Features temporais", value=True)
    
    st.subheader("üéØ Sele√ß√£o de Features")
    usar_selecao = st.checkbox("Sele√ß√£o autom√°tica de features", value=True)
    n_features = st.slider("N√∫mero de features (se sele√ß√£o ativa)", 10, 50, 20) if usar_selecao else None
    
    normalizar = st.checkbox("Normaliza√ß√£o (StandardScaler)", value=True)

# =============================================================================
# FUN√á√ïES UTILIT√ÅRIAS
# =============================================================================
@st.cache_data
def carregar_e_processar_dados(arquivo):
    """Carrega e processa os dados b√°sicos"""
    df = pd.read_csv(arquivo)
    
    # Normalizar nomes das colunas
    df.columns = (
        df.columns
        .str.strip()
        .str.lower()
        .str.replace(" ", "_")
        .str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    )
    
    return df

def criar_features_avancadas(df):
    """Aplica engenharia de features"""
    df = df.copy()
    
    # Features b√°sicas de engenharia
    if usar_dif_temp and {"temperatura_processo","temperatura_ar"}.issubset(df.columns):
        df["dif_temperatura"] = df["temperatura_processo"] - df["temperatura_ar"]
        df["razao_temperatura"] = df["temperatura_processo"] / (df["temperatura_ar"] + 1e-6)
        df["temp_normalizada"] = (df["temperatura_processo"] - df["temperatura_ar"].mean()) / (df["temperatura_ar"].std() + 1e-6)
    
    if usar_potencia and {"torque","velocidade_rotacional"}.issubset(df.columns):
        df["potencia_kw"] = (df["torque"] * df["velocidade_rotacional"]) / 1000.0
        df["potencia_especifica"] = df["potencia_kw"] / (df["desgaste_da_ferramenta"] + 1.0)
        df["torque_por_velocidade"] = df["torque"] / (df["velocidade_rotacional"] + 1.0)
    
    if usar_eficiencia and {"torque","desgaste_da_ferramenta"}.issubset(df.columns):
        df["eficiencia_ferramenta"] = df["torque"] / (df["desgaste_da_ferramenta"] + 1.0)
        df["desgaste_normalizado"] = df["desgaste_da_ferramenta"] / (df["torque"] + 1e-6)
        df["stress_ferramenta"] = df["torque"] * df["desgaste_da_ferramenta"]
    
    # Features baseadas em s√©ries temporais (simuladas atrav√©s do √≠ndice)
    if usar_series_temporais:
        window_size = min(10, len(df) // 4)
        if window_size > 2:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in ['temperatura_processo', 'torque', 'velocidade_rotacional']:
                if col in numeric_cols:
                    df[f"{col}_media_movel"] = df[col].rolling(window=window_size, min_periods=1).mean()
                    df[f"{col}_desvio_movel"] = df[col].rolling(window=window_size, min_periods=1).std().fillna(0)
                    df[f"{col}_tendencia"] = df[col].diff().fillna(0)
    
    # Features de intera√ß√£o entre vari√°veis
    if usar_interacoes:
        if all(col in df.columns for col in ["temperatura_processo", "umidade_relativa"]):
            df["temp_umidade_interacao"] = df["temperatura_processo"] * df["umidade_relativa"]
        
        if all(col in df.columns for col in ["torque", "umidade_relativa"]):
            df["torque_umidade_interacao"] = df["torque"] * df["umidade_relativa"]
            
        if all(col in df.columns for col in ["velocidade_rotacional", "temperatura_processo"]):
            df["velocidade_temp_interacao"] = df["velocidade_rotacional"] * df["temperatura_processo"]
    
    return df

def otimizar_hiperparametros(modelo, X, y, algoritmo_nome, tipo_busca="RandomizedSearch"):
    """Otimiza hiperpar√¢metros do modelo"""
    
    param_grids = {
        "Random Forest": {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        },
        "Gradient Boosting": {
            'n_estimators': [100, 200],
            'max_depth': [3, 6, 10],
            'learning_rate': [0.01, 0.1, 0.2],
            'subsample': [0.8, 1.0]
        },
        "Neural Network": {
            'hidden_layer_sizes': [(50,), (100,), (50, 30)],
            'activation': ['relu', 'tanh'],
            'alpha': [0.0001, 0.001, 0.01],
            'learning_rate': ['adaptive', 'constant']
        },
        "SVM": {
            'C': [0.1, 1, 10],
            'gamma': ['scale', 'auto'],
            'kernel': ['rbf', 'linear']
        }
    }
    
    if algoritmo_nome not in param_grids:
        return modelo
    
    param_grid = param_grids[algoritmo_nome]
    
    try:
        if tipo_busca == "GridSearch":
            search = GridSearchCV(modelo, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
        else:
            search = RandomizedSearchCV(modelo, param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)
        
        search.fit(X, y)
        return search.best_estimator_
    except:
        return modelo

def criar_ensemble(X_train, y_train, tipo_modelagem):
    """Cria ensemble de modelos"""
    modelos_base = {
        'rf': RandomForestClassifier(n_estimators=100, random_state=42),
        'gb': GradientBoostingClassifier(n_estimators=100, random_state=42),
        'nn': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),
        'dt': DecisionTreeClassifier(random_state=42)
    }
    
    if tipo_modelagem == "Multirr√≥tulo":
        ensemble_models = {}
        for name, model in modelos_base.items():
            try:
                ensemble_models[name] = MultiOutputClassifier(model)
                ensemble_models[name].fit(X_train, y_train)
            except:
                continue
        return ensemble_models
    else:
        # Para bin√°rio/multiclasse, usar VotingClassifier
        try:
            ensemble = VotingClassifier(
                estimators=list(modelos_base.items()),
                voting='soft'
            )
            ensemble.fit(X_train, y_train)
            return ensemble
        except:
            # Fallback para Random Forest
            rf = RandomForestClassifier(n_estimators=200, random_state=42)
            rf.fit(X_train, y_train)
            return rf

# Carregar dados
dados_treino = None
dados_teste = None

if arquivo_treino:
    try:
        dados_treino = carregar_e_processar_dados(arquivo_treino)
        st.success(f"‚úÖ Dados de treino carregados: {dados_treino.shape[0]} amostras √ó {dados_treino.shape[1]} features")
    except Exception as e:
        st.error(f"Erro ao carregar dados de treino: {str(e)}")
        st.stop()
    
if arquivo_teste:
    try:
        dados_teste = carregar_e_processar_dados(arquivo_teste)
        st.success(f"‚úÖ Dados de teste carregados: {dados_teste.shape[0]} amostras")
    except Exception as e:
        st.error(f"Erro ao carregar dados de teste: {str(e)}")

if dados_treino is None:
    st.warning("‚è≥ Por favor, carregue o arquivo de treino para continuar.")
    st.stop()

# =============================================================================
# SE√á√ÉO 3: AN√ÅLISE EXPLORAT√ìRIA
# =============================================================================
st.header("üìä 3. AN√ÅLISE EXPLORAT√ìRIA")

# Aplicar engenharia de features
try:
    dados_processados = criar_features_avancadas(dados_treino)
except Exception as e:
    st.error(f"Erro na cria√ß√£o de features: {str(e)}")
    dados_processados = dados_treino.copy()

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("üìä Total de Amostras", dados_processados.shape[0])
with col2:
    st.metric("üìà Features Originais", dados_treino.shape[1])
with col3:
    st.metric("üîß Features Criadas", dados_processados.shape[1] - dados_treino.shape[1])
with col4:
    st.metric("üìä Total de Features", dados_processados.shape[1])

if all(col in dados_processados.columns for col in COLS_FALHA):
    # An√°lise de desbalanceamento
    st.subheader("‚öñÔ∏è An√°lise de Desbalanceamento")
    
    falhas_count = dados_processados[COLS_FALHA].sum().sort_values(ascending=False)
    total_amostras = len(dados_processados)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Tabela de estat√≠sticas
        df_stats = pd.DataFrame({
            'Tipo_Falha': falhas_count.index,
            'Quantidade': falhas_count.values,
            'Percentual': (falhas_count.values / total_amostras * 100).round(2),
            'Classe': ['Minorit√°ria' if x < total_amostras * 0.1 else 'Majorit√°ria' for x in falhas_count.values]
        })
        
        st.dataframe(df_stats, use_container_width=True)
        
        # Calcular raz√£o de desbalanceamento
        if falhas_count.min() > 0:
            ratio_desbalanceamento = falhas_count.max() / falhas_count.min()
            st.metric("üîÑ Raz√£o de Desbalanceamento", f"{ratio_desbalanceamento:.1f}:1")
    
    with col2:
        # Gr√°fico de distribui√ß√£o
        fig = px.bar(
            df_stats, 
            x='Quantidade', 
            y='Tipo_Falha',
            color='Classe',
            orientation='h',
            title="Distribui√ß√£o das Classes de Falhas"
        )
        st.plotly_chart(fig, use_container_width=True)

# =============================================================================
# SE√á√ÉO 4: PREPARA√á√ÉO DOS DADOS
# =============================================================================
st.header("üîß 4. PREPARA√á√ÉO DOS DADOS")

# Preparar features (X) e targets (y)
excluir_cols = {"id", "id_produto", "tipo", COL_ALVO_BINARIA} | set(COLS_FALHA)
features_cols = [col for col in dados_processados.columns if col not in excluir_cols]

# Tratar valores categ√≥ricos
if "tipo" in dados_processados.columns:
    try:
        le_tipo = LabelEncoder()
        dados_processados["tipo_encoded"] = le_tipo.fit_transform(dados_processados["tipo"].fillna("Unknown"))
        features_cols.append("tipo_encoded")
    except:
        pass

# Preparar matriz X
X = dados_processados[features_cols].copy()
X = X.fillna(X.median())

# Sele√ß√£o autom√°tica de features
if usar_selecao and n_features:
    st.subheader("üéØ Sele√ß√£o Autom√°tica de Features")
    
    # Preparar y tempor√°rio para sele√ß√£o
    if all(col in dados_processados.columns for col in COLS_FALHA):
        y_temp = dados_processados[COLS_FALHA].max(axis=1)
    else:
        y_temp = dados_processados.get(COL_ALVO_BINARIA, pd.Series([0]*len(dados_processados)))
    
    try:
        selector = SelectKBest(f_classif, k=min(n_features, X.shape[1]))
        X_selected = selector.fit_transform(X, y_temp)
        selected_features = [features_cols[i] for i in selector.get_support(indices=True)]
        X = pd.DataFrame(X_selected, columns=selected_features, index=X.index)
        features_cols = selected_features
        st.success(f"‚úÖ {len(selected_features)} features selecionadas")
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel aplicar sele√ß√£o de features: {str(e)}")

# Normaliza√ß√£o
scaler = None
if normalizar:
    try:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
    except Exception as e:
        st.warning(f"Erro na normaliza√ß√£o: {str(e)}")

# Preparar targets
if tipo_modelagem == "Multirr√≥tulo":
    if not all(col in dados_processados.columns for col in COLS_FALHA):
        st.error("‚ùå Dados n√£o cont√™m colunas necess√°rias para modelagem multirr√≥tulo.")
        st.stop()
    y = dados_processados[COLS_FALHA].values
    target_names = COLS_FALHA
    
elif tipo_modelagem == "Bin√°ria":
    if COL_ALVO_BINARIA not in dados_processados.columns:
        st.error("‚ùå Coluna 'falha_maquina' n√£o encontrada para modelagem bin√°ria.")
        st.stop()
    y = dados_processados[COL_ALVO_BINARIA].values
    target_names = ["Sem Falha", "Com Falha"]
    
else:  # Multiclasse
    if not all(col in dados_processados.columns for col in COLS_FALHA):
        st.error("‚ùå Dados n√£o cont√™m colunas necess√°rias para modelagem multiclasse.")
        st.stop()
    
    def get_primary_failure(row):
        failures = [col for col in COLS_FALHA if row[col] == 1]
        if len(failures) == 0:
            return "sem_falha"
        elif len(failures) == 1:
            return failures[0]
        else:
            return "multiplas_falhas"
    
    y_multiclass = dados_processados[COLS_FALHA].apply(get_primary_failure, axis=1)
    le_target = LabelEncoder()
    y = le_target.fit_transform(y_multiclass)
    target_names = le_target.classes_

st.write(f"**Features finais utilizadas:** {len(features_cols)} features")

# =============================================================================
# SE√á√ÉO 5: MODELAGEM
# =============================================================================
st.header("ü§ñ 5. MODELAGEM")

# Dividir dados
try:
    if tipo_modelagem == "Multirr√≥tulo":
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=percentual_teste/100, random_state=semente
        )
    else:
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=percentual_teste/100, random_state=semente, 
            stratify=y if len(np.unique(y)) > 1 else None
        )
    
    st.write(f"üìä **Divis√£o dos dados:** {len(X_train)} treino / {len(X_val)} valida√ß√£o")
except Exception as e:
    st.error(f"Erro na divis√£o dos dados: {str(e)}")
    st.stop()

# Treinar modelos
resultados_modelos = {}

with st.spinner("üîÑ Treinando modelo..."):
    try:
        if algoritmo == "Ensemble":
            modelo = criar_ensemble(X_train, y_train, tipo_modelagem)
        else:
            # Treinar modelo individual
            modelos_disponiveis = {
                "Random Forest": RandomForestClassifier(n_estimators=200, random_state=semente),
                "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=semente),
                "Neural Network": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=semente),
                "SVM": SVC(probability=True, random_state=semente)
            }
            
            modelo_base = modelos_disponiveis[algoritmo]
            
            # Otimiza√ß√£o de hiperpar√¢metros
            if otimizar_hiper and tipo_modelagem != "Multirr√≥tulo":
                st.write(f"üîç Otimizando hiperpar√¢metros...")
                modelo_base = otimizar_hiperparametros(modelo_base, X_train, y_train, algoritmo, tipo_busca)
            
            # Aplicar MultiOutputClassifier se necess√°rio
            if tipo_modelagem == "Multirr√≥tulo":
                modelo = MultiOutputClassifier(modelo_base)
            else:
                modelo = modelo_base
            
            modelo.fit(X_train, y_train)
        
        st.success("‚úÖ Modelo treinado com sucesso!")
        
    except Exception as e:
        st.error(f"Erro no treinamento: {str(e)}")
        st.stop()

# Fazer predi√ß√µes
try:
    y_pred = modelo.predict(X_val)
except Exception as e:
    st.error(f"Erro nas predi√ß√µes: {str(e)}")
    st.stop()

# =============================================================================
# SE√á√ÉO 6: AVALIA√á√ÉO
# =============================================================================
st.header("üìä 6. AVALIA√á√ÉO DOS RESULTADOS")

try:
    if tipo_modelagem == "Multirr√≥tulo":
        # M√©tricas detalhadas por classe
        st.subheader("üìà M√©tricas por Tipo de Falha")
        
        metricas_detalhadas = {}
        cols_display = st.columns(len(COLS_FALHA))
        
        for i, col_falha in enumerate(COLS_FALHA):
            accuracy = accuracy_score(y_val[:, i], y_pred[:, i])
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_val[:, i], y_pred[:, i], average='binary', zero_division=0
            )
            
            metricas_detalhadas[col_falha] = {
                'Accuracy': accuracy,
                'Precision': precision,
                'Recall': recall,
                'F1-Score': f1
            }
            
            with cols_display[i]:
                st.metric(f"üéØ {col_falha.upper()}", f"{accuracy:.3f}")
                st.write(f"Precision: {precision:.3f}")
                st.write(f"Recall: {recall:.3f}")
                st.write(f"F1: {f1:.3f}")
        
        # M√©tricas m√©dias
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            acc_media = np.mean([metricas_detalhadas[col]['Accuracy'] for col in COLS_FALHA])
            st.metric("üèÜ Accuracy M√©dia", f"{acc_media:.4f}")
        with col2:
            prec_media = np.mean([metricas_detalhadas[col]['Precision'] for col in COLS_FALHA])
            st.metric("üéØ Precision M√©dia", f"{prec_media:.4f}")
        with col3:
            rec_media = np.mean([metricas_detalhadas[col]['Recall'] for col in COLS_FALHA])
            st.metric("üìä Recall M√©dio", f"{rec_media:.4f}")
        with col4:
            f1_media = np.mean([metricas_detalhadas[col]['F1-Score'] for col in COLS_FALHA])
            st.metric("‚öñÔ∏è F1 M√©dio", f"{f1_media:.4f}")

    else:
        # Modelo bin√°rio ou multiclasse
        accuracy = accuracy_score(y_val, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_val, y_pred, average='weighted', zero_division=0
        )
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üéØ Accuracy", f"{accuracy:.4f}")
        with col2:
            st.metric("üîç Precision", f"{precision:.4f}")
        with col3:
            st.metric("üìä Recall", f"{recall:.4f}")
        with col4:
            st.metric("‚öñÔ∏è F1-Score", f"{f1:.4f}")
        
        # Matriz de confus√£o
        st.subheader("üîç Matriz de Confus√£o")
        
        cm = confusion_matrix(y_val, y_pred)
        fig_cm = px.imshow(
            cm, 
            text_auto=True, 
            aspect="auto", 
            title="Matriz de Confus√£o",
            color_continuous_scale="Blues"
        )
        fig_cm.update_xaxes(title="Predito")
        fig_cm.update_yaxes(title="Real")
        st.plotly_chart(fig_cm, use_container_width=True)

except Exception as e:
    st.error(f"Erro na avalia√ß√£o: {str(e)}")

# Feature Importance
st.subheader("üéØ Import√¢ncia das Features")

try:
    importances = None
    if algoritmo == "Ensemble" and hasattr(modelo, 'feature_importances_'):
        importances = modelo.feature_importances_
    elif algoritmo == "Ensemble" and isinstance(modelo, dict):
        # Para ensemble multirr√≥tulo
        if 'rf' in modelo:
            importances = np.mean([est.feature_importances_ for est in modelo['rf'].estimators_], axis=0)
    elif hasattr(modelo, 'feature_importances_'):
        importances = modelo.feature_importances_
    elif tipo_modelagem == "Multirr√≥tulo" and hasattr(modelo, 'estimators_'):
        importances = np.mean([est.feature_importances_ for est in modelo.estimators_ 
                              if hasattr(est, 'feature_importances_')], axis=0)
    
    if importances is not None and len(importances) == len(features_cols):
        feature_importance_df = pd.DataFrame({
            'Feature': features_cols,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        
        fig_importance = px.bar(
            feature_importance_df.head(15), 
            x='Importance', 
            y='Feature',
            orientation='h',
            title="Top 15 Features Mais Importantes"
        )
        fig_importance.update_layout(height=500)
        st.plotly_chart(fig_importance, use_container_width=True)
    else:
        st.info("Import√¢ncia das features n√£o dispon√≠vel para este modelo.")

except Exception as e:
    st.warning(f"N√£o foi poss√≠vel calcular import√¢ncia das features: {str(e)}")

# =============================================================================
# SE√á√ÉO 7: PREDI√á√ïES NO TESTE
# =============================================================================
if dados_teste is not None:
    st.header("üéØ 7. PREDI√á√ïES NO CONJUNTO DE TESTE")
    
    try:
        # Processar dados de teste
        dados_teste_proc = criar_features_avancadas(dados_teste)
        
        if "tipo" in dados_teste_proc.columns and 'le_tipo' in locals():
            dados_teste_proc["tipo_encoded"] = le_tipo.transform(
                dados_teste_proc["tipo"].fillna("Unknown")
            )
        
        # Preparar X_test com as mesmas features
        X_test = dados_teste_proc[features_cols].copy()
        X_test = X_test.fillna(X_test.median())
        
        if scaler is not None:
            X_test = pd.DataFrame(
                scaler.transform(X_test), 
                columns=X_test.columns, 
                index=X_test.index
            )
        
        # Gerar predi√ß√µes
        if tipo_modelagem == "Multirr√≥tulo":
            if algoritmo == "Ensemble" and isinstance(modelo, dict):
                # M√©dia das predi√ß√µes do ensemble
                predicoes_teste = {}
                for name, model in modelo.items():
                    try:
                        predicoes_teste[name] = model.predict(X_test)
                    except:
                        continue
                
                if predicoes_teste:
                    pred_test = np.round(np.mean([pred for pred in predicoes_teste.values()], axis=0)).astype(int)
                else:
                    pred_test = np.zeros((len(X_test), len(COLS_FALHA)))
            else:
                pred_test = modelo.predict(X_test)
            
            # Criar DataFrame de sa√≠da
            df_predicoes = pd.DataFrame(
                pred_test, 
                columns=[col.upper() for col in COLS_FALHA]
            ).astype(int)
            
        else:
            pred_test = modelo.predict(X_test)
            
            # Para bin√°rio/multiclasse, criar formato multirr√≥tulo
            df_predicoes = pd.DataFrame(
                0, 
                index=range(len(pred_test)), 
                columns=[col.upper() for col in COLS_FALHA]
            )
            
            if tipo_modelagem == "Bin√°ria":
                # Atribuir falha mais comum quando h√° predi√ß√£o positiva
                falha_mais_comum = dados_processados[COLS_FALHA].sum().idxmax().upper()
                df_predicoes.loc[pred_test == 1, falha_mais_comum] = 1
                
            else:  # Multiclasse
                for i, pred in enumerate(pred_test):
                    classe_nome = target_names[pred]
                    if classe_nome in [col.lower() for col in COLS_FALHA]:
                        col_idx = [col.lower() for col in COLS_FALHA].index(classe_nome)
                        df_predicoes.iloc[i, col_idx] = 1
        
        # Estat√≠sticas das predi√ß√µes
        st.subheader("üìä Estat√≠sticas das Predi√ß√µes")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Contagem por tipo de falha:**")
            contagem_pred = df_predicoes.sum().to_frame("Quantidade")
            contagem_pred["Percentual"] = (contagem_pred["Quantidade"] / len(df_predicoes) * 100).round(2)
            st.dataframe(contagem_pred, use_container_width=True)
        
        with col2:
            # Gr√°fico de barras das predi√ß√µes
            fig_pred = px.bar(
                x=df_predicoes.sum().values,
                y=df_predicoes.sum().index,
                orientation='h',
                title="Distribui√ß√£o das Predi√ß√µes por Tipo de Falha"
            )
            st.plotly_chart(fig_pred, use_container_width=True)
        
        # Download das predi√ß√µes
        csv_predicoes = df_predicoes.to_csv(index=False)
        st.download_button(
            "üì• Baixar Predi√ß√µes (CSV)",
            csv_predicoes,
            "bootcamp_predictions.csv",
            "text/csv"
        )
        
        st.success("‚úÖ Predi√ß√µes geradas com sucesso!")
        
    except Exception as e:
        st.error(f"Erro ao processar dados de teste: {str(e)}")

# =============================================================================
# SE√á√ÉO 8: INSIGHTS E RECOMENDA√á√ïES
# =============================================================================
st.header("üìä 8. INSIGHTS E RECOMENDA√á√ïES")

col1, col2 = st.columns(2)

with col1:
    st.subheader("üîç Insights do Modelo")
    
    insights = []
    
    # Insights baseados na performance
    if tipo_modelagem == "Multirr√≥tulo" and 'metricas_detalhadas' in locals():
        f1_scores = [metricas_detalhadas[col]['F1-Score'] for col in COLS_FALHA]
        melhor_classe = max(metricas_detalhadas.keys(), 
                           key=lambda x: metricas_detalhadas[x]['F1-Score'])
        pior_classe = min(metricas_detalhadas.keys(), 
                         key=lambda x: metricas_detalhadas[x]['F1-Score'])
        
        insights.append(f"üéØ **Melhor predi√ß√£o:** {melhor_classe.upper()}")
        insights.append(f"‚ö†Ô∏è **Maior desafio:** {pior_classe.upper()}")
        insights.append(f"üìä **F1 m√©dio:** {np.mean(f1_scores):.3f}")
    
    elif tipo_modelagem != "Multirr√≥tulo" and 'accuracy' in locals():
        insights.append(f"üéØ **Accuracy geral:** {accuracy:.3f}")
    
    # Insights sobre features
    if 'feature_importance_df' in locals():
        top_feature = feature_importance_df.iloc[0]
        insights.append(f"üîß **Feature mais importante:** {top_feature['Feature']}")
    
    # Insights sobre dados
    insights.append(f"üìä **Total de features utilizadas:** {len(features_cols)}")
    insights.append(f"üîß **Features criadas:** {dados_processados.shape[1] - dados_treino.shape[1]}")
    
    for insight in insights:
        st.markdown(insight)

with col2:
    st.subheader("üí° Recomenda√ß√µes")
    
    recomendacoes = [
        "üìà Implementar monitoramento cont√≠nuo da performance",
        "üîÑ Considerar retreinamento peri√≥dico com novos dados",
        "‚ö° Desenvolver sistema de alertas baseado nas predi√ß√µes",
        "üè≠ Integrar com sistema de gest√£o de manuten√ß√£o existente",
        "üìä Coletar feedback dos t√©cnicos para melhorar o modelo",
        "üéØ Focar na coleta de mais dados para classes minorit√°rias"
    ]
    
    for rec in recomendacoes:
        st.markdown(f"- {rec}")

# =============================================================================
# SE√á√ÉO 9: CONCLUS√ïES
# =============================================================================
st.header("üìã 9. CONCLUS√ïES")

with st.expander("üéØ Principais Conclus√µes", expanded=True):
    st.markdown(f"""
    ### ‚úÖ **Resultados Alcan√ßados:**
    
    1. **Sistema Completo de Manuten√ß√£o Preditiva:**
       - An√°lise explorat√≥ria com {dados_processados.shape[1]} features
       - Engenharia de features criou {dados_processados.shape[1] - dados_treino.shape[1]} novas vari√°veis
       - Implementa√ß√£o de m√∫ltiplos algoritmos de ML
       - Sistema pronto para produ√ß√£o
    
    2. **Performance do Modelo:**
       - Algoritmo utilizado: **{algoritmo}**
       - Abordagem: **{tipo_modelagem}**
       - Otimiza√ß√£o de hiperpar√¢metros: **{'Sim' if otimizar_hiper else 'N√£o'}**
       - Features utilizadas: **{len(features_cols)}**
    
    3. **Impacto no Neg√≥cio:**
       - Sistema pronto para detec√ß√£o precoce de falhas
       - Redu√ß√£o esperada de custos de manuten√ß√£o
       - Melhoria na disponibilidade dos equipamentos
       - Interface intuitiva para operadores
    """)

# =============================================================================
# DASHBOARD EXECUTIVO
# =============================================================================
st.header("üìä Dashboard Executivo")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("üìä Amostras Processadas", f"{dados_processados.shape[0]:,}")
with col2:
    st.metric("üîß Features Totais", dados_processados.shape[1])
with col3:
    if tipo_modelagem == "Multirr√≥tulo" and 'metricas_detalhadas' in locals():
        perf_media = np.mean([metricas_detalhadas[col]['F1-Score'] for col in COLS_FALHA])
        st.metric("üéØ Performance M√©dia", f"{perf_media:.3f}")
    elif 'accuracy' in locals():
        st.metric("üéØ Accuracy Final", f"{accuracy:.3f}")
    else:
        st.metric("üéØ Modelo", "Treinado ‚úÖ")
with col4:
    if dados_teste is not None and 'df_predicoes' in locals():
        falhas_previstas = df_predicoes.sum().sum()
        st.metric("‚ö†Ô∏è Falhas Previstas", int(falhas_previstas))
    else:
        st.metric("üíæ Status", "Pronto ‚úÖ")

# =============================================================================
# RODAP√â
# =============================================================================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <h4>üîß Sistema Inteligente de Manuten√ß√£o Preditiva</h4>
    <p><strong>Bootcamp de Ci√™ncia de Dados e IA - Projeto Final</strong></p>
    <p>Desenvolvido com Python, Scikit-learn e Streamlit</p>
    <p><em>Vers√£o otimizada para compatibilidade com Streamlit Cloud</em></p>
</div>
""", unsafe_allow_html=True)
