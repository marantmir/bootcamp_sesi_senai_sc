"""
Streamlit front-end para o projeto de Manuten√ß√£o Preditiva do Bootcamp.
- Upload de Bootcamp_train.csv (obrigat√≥rio) e Bootcamp_test.csv (opcional)
- Detec√ß√£o / mapeamento das colunas de falha (interface para confirmar)
- Pr√©-processamento, compara√ß√£o de modelos e gera√ß√£o de submiss√£o
"""
import streamlit as st
import pandas as pd
import traceback, sys

from utils import carregar_e_processar_dados, detect_failure_columns, preprocess_pipeline
from modelos import comparar_e_treinar_modelos, gerar_predicoes_para_submissao

st.set_page_config(page_title="üîß Manuten√ß√£o Preditiva", page_icon="üîß", layout="wide")
st.title("üîß Sistema Inteligente de Manuten√ß√£o Preditiva")

st.markdown("""
Carregue:
- **Bootcamp_train.csv** (obrigat√≥rio) ‚Äî cont√©m r√≥tulos.
- **Bootcamp_test.csv** (opcional) ‚Äî sem r√≥tulos; ser√° usado para gerar `predicoes_submission.csv`.
""")

arquivo_treino = st.file_uploader("üìÇ Selecione Bootcamp_train.csv", type=["csv"])
arquivo_teste = st.file_uploader("üìÇ Selecione Bootcamp_test.csv (opcional)", type=["csv"])

if arquivo_treino:
    try:
        treino_df = carregar_e_processar_dados(arquivo_treino)
        teste_df = carregar_e_processar_dados(arquivo_teste) if arquivo_teste else None

        st.success("‚úÖ Arquivo de treino carregado.")
        st.write("Preview (treino):")
        st.dataframe(treino_df.head())

        st.markdown("### 1) Detec√ß√£o autom√°tica das colunas de falha")
        detection = detect_failure_columns(treino_df)
        st.write("Mapeamento autom√°tico (aliases):")
        st.json(detection["detected_map"])
        st.write("Colunas 0/1 candidatas:", detection["candidate_binary_cols"])

        st.markdown("### 2) Confirme/ajuste o mapeamento (se necess√°rio)")
        canonical = ["fdf", "fdc", "fp", "fte", "fa"]
        cols_options = [""] + detection["all_columns"]
        user_map = {}
        for can in canonical:
            default = detection["detected_map"].get(can) if detection["detected_map"].get(can) else ""
            idx = cols_options.index(default) if default in cols_options else 0
            user_map[can] = st.selectbox(f"Coluna para {can.upper()}", options=cols_options, index=idx, key=f"map_{can}")

        if st.button("‚úÖ Confirmar mapeamento e executar pipeline"):
            if not all(user_map.values()):
                st.error("Selecione as 5 colunas de falha antes de continuar.")
            else:
                target_columns_actual = [user_map[c] for c in canonical]
                st.info("Rodando pr√©-processamento (pode levar alguns segundos)...")
                X_train, X_val, y_train, y_val, X_test_proc, preprocess_objects, features, detected = preprocess_pipeline(
                    treino_df, teste_df, target_columns=target_columns_actual, verbose=False
                )

                st.success("Pr√©-processamento conclu√≠do.")
                st.write(f"Features usadas ({len(features)}):")
                st.code(features)

                st.markdown("### 3) Treinamento e compara√ß√£o de modelos")
                st.info("Treinando e comparando: RandomForest (sempre), LightGBM e XGBoost (se dispon√≠veis).")
                results, best_model = comparar_e_treinar_modelos(X_train, y_train, X_val, y_val)

                # Mostrar resultados
                df_results = pd.DataFrame([{
                    "model_name": r["model_name"],
                    "mean_f1": r["mean_f1"],
                    "hamming_loss": r["hamming_loss"],
                    "subset_acc": r["subset_acc"]
                } for r in results]).sort_values("mean_f1", ascending=False).reset_index(drop=True)

                st.dataframe(df_results)
                st.success(f"Melhor modelo: {results[0]['model_name']} (ver tabela)")

                st.markdown("#### M√©tricas detalhadas (melhor modelo)")
                best_detail = results[0]
                st.write("Per-label F1 (valida√ß√£o):")
                st.json(best_detail["per_label_f1"])

                # gerar predi√ß√µes para teste se existir
                if X_test_proc is not None:
                    st.markdown("### 4) Gerar predi√ß√µes para submiss√£o")
                    df_pred = gerar_predicoes_para_submissao(
                        best_model,
                        X_test_proc,
                        canonical_targets=preprocess_objects["canonical_targets"],
                        target_map=preprocess_objects["target_columns_actual"],
                        original_test_df=teste_df
                    )
                    st.write("Amostra das predi√ß√µes:")
                    st.dataframe(df_pred.head())
                    csv_bytes = df_pred.to_csv(index=False).encode("utf-8")
                    st.download_button("üì• Baixar predicoes_submission.csv", csv_bytes, "predicoes_submission.csv", "text/csv")
                    st.info("Pronto ‚Äî envie o arquivo √† API de avalia√ß√£o do Bootcamp.")
                else:
                    st.info("Nenhum Bootcamp_test.csv foi fornecido ‚Äî carregue-o para gerar submiss√µes.")
    except Exception as e:
        tb = traceback.format_exc()
        st.error("‚ùå Erro no processamento. Veja o traceback abaixo:")
        st.code(tb)
        print(tb, file=sys.stderr)
else:
    st.info("Fa√ßa upload do Bootcamp_train.csv para come√ßar.")
